---
title: "EXAM"
author: "Mariateresa Russo e Angelo Capasso"
format:
  revealjs:
    theme: solarized
    highlight: pygments
    center: true
    transition: fade
    background-transition: slide
    slide-number: true
    preview-links: true
    code-fold: true
    code-summary: "code"
---

```{r setup, include = FALSE, echo = FALSE}
library(tidymodels)
library(tidyverse)
library(GGally)
library(ggplot2)
library(FactoMineR)
library(factoextra)
library(Rdimtools)
library(readr)
library(janitor)
library(knitr)
library(patchwork)
library(gridExtra)
library(lattice)
library(plotly)
library(clustrd)
library(mclust)
library(cluster)
library(VIM)
library(rpart)
library(kknn)
library(dplyr)
library(tidyr)
library(purrr)
library(rattle)
library(iml)
library(lime)
library(pheatmap)
library(treemapify)
library(plotly)
library(ranger)
library(yardstick)
library(tibble)
```

```{r, echo = FALSE, warning=FALSE, include=FALSE}
support2 <- read_csv("support2.csv")

data = support2
```

```{r, echo = FALSE, warning=FALSE, include=FALSE}
colnames(data) <- c("id", "age", "death", "sex", "hospdead", "slos", "d.time", "dzgroup", "dzclass", "num.co", "edu", "income", "scoma", "charges", "totcst", "totmcst", "avtisst", "race", "sps", "aps", "surv2m", "surv6m", "hday", "diabetes", "dementia", "ca", "prg2m", "prg6m", "dnr", "dnrday", "meanbp", "wblc", "hrt", "resp", "temp", "pafi", "alb", "bili", "crea", "sod", "ph", "glucose", "bun", "urine", "adlp", "adls", "sfdm2")

data <- data |>
  dplyr::mutate(
    across(c(where(is.character), death, hospdead, 
                  diabetes, income, dementia), ~ factor(.x))) |> 
  dplyr::select(-c(id, scoma, sps, surv2m, surv6m, sfdm2))
```

# 1) Dataset

## Numerical Features

::: {style="font-size: 37%;"}
-   **age**: age  
-   **slos**: length of hospital stay (days)  
-   **d.time**: follow-up time (days) 
-   **hday**: number of hospital days up to the clinical event (discharge or death)
-   **num.co**: number of comorbidities  
-   **edu**: years of education  
-   **charges**: charges billed to the patient  
-   **totcst**: cost estimated by the RCC index  
-   **totmcst**: actual cost billed considering bonuses  
-   **avtisst**: Therapeutic Intervention Scoring System (intensity of care)  
-   **aps**: Acute Physiology Score (vital conditions assessment)  
-   **meanbp**: mean blood pressure  
-   **wblc**: white blood cell count  
-   **hrt**: heart rate  
-   **resp**: respiratory rate  
-   **temp**: body temperature  
-   **pafi**: PaO2/FiO2 ratio  
-   **alb**: albumin  
-   **bili**: bilirubin  
-   **crea**: creatinine  
-   **sod**: sodium  
-   **ph**: blood pH  
-   **glucose**, **bun**, **urine**  
-   **adlp**, **adls**: scores indicating daily living activities  
-   **dnrday**: day of the DNR (do-not-resuscitate) decision  
-   **prg2m**, **prg6m**: survival probability at 2 and 6 months  
:::

## Categorical Features

::: {style="font-size: 60%;"}
-   **death**: 0 = alive, 1 = deceased  
-   **sex**: male / female  
-   **hospdead**: death in hospital (0/1)  
-   **diabetes**, **dementia**: presence/absence  
-   **dzgroup**: diagnostic group (e.g., Lung Cancer, Cirrhosis, ARF/MOSF)  
-   **dzclass**: broader diagnostic class  
-   **income**: income category  
-   **race**: white, black, other  
-   **ca**: cancer category (none / local / metastatic)  
-   **dnr**: DNR status (do-not-resuscitate)  
-   **sfdm2**: functional status at 2 months 
:::

# 2) Esplorative Data Analysis

## Missing values

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
missing_summary <- tibble(
  variabile = names(data),
  n_na      = colSums(is.na(data)),
  perc_na   = colMeans(is.na(data)) * 100
) |>
  dplyr::filter(n_na > 0) |>         
  arrange(desc(perc_na))

ggplot(missing_summary, aes(x = reorder(variabile, perc_na), y = perc_na)) +
  geom_col(fill = "#8FD4B8") +
  coord_flip() +
  labs(title = "Features with missing values",
       x = "Feature", y = "% NA")
```

## Numerical Features

### Correlation matrix

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
num_data <- data[, sapply(data, is.numeric)]

corr_mat <- cor(num_data, use = "pairwise.complete.obs")

levelplot(
  corr_mat,
  scales = list(x = list(rot = 45)),
  xlab = " ",
  ylab = " ",
  main = "Correlation Heatmap",
  col.regions = colorRampPalette(c("#2A5783", "white", "#F07F28"))(100)
)
```

### Hierarchical Clustering

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
dist_mat <- as.dist(1 - corr_mat)

hc <- hclust(dist_mat, method = "complete")

plot(hc, main = "Hierarchical Clustering")
```

## Categorical Features

```{r, warning=FALSE}
#| echo: true
#| code-fold: true
#| code-summary: "code"
data %>%
  dplyr::select(where(is.factor)) %>%
  tidyr::pivot_longer(cols = everything(), names_to = "variabile", values_to = "valore") %>%
  ggplot(aes(x = valore, y = ..prop.., group = 1, fill = valor)) +
  geom_bar(fill = "#8FD4B8") +
  facet_wrap(~ variabile, scales = "free") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Categorical Features-frequency distribution",
       x = "Category", y = "Percentage") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none",
        strip.text = element_text(size = 10))

```

## Manage Missing Values

::: {style="font-size: 50%;"}
-Remove features with more than 30% NA: bun, urine, glucose, adlp

```{r}
data <- data |> dplyr::select(-c(
  adlp, urine, glucose, bun, totmcst, alb, adls, bili, pafi, ph,
  prg2m, edu, prg6m, totcst))
```

-Remove features correlated with other features: avtisst, dnrday

```{r}
data <- data |> 
  dplyr::select(-c(avtisst, dnrday))
# adls adlp
# totmcst totcst charges
# aps avtisst
# dnrday slos
```

-Imputation for other features: income, wblc, charges, crea, race, dnr
```{r}
#| echo: false
#| code-fold: true
#| code-summary: "code"
#| 
data <- data |>
  dplyr::mutate(income = fct_explicit_na(income, na_level = "nd"))

library(VIM)
set.seed(6)
data_imp <- VIM::kNN(data, variable = c("wblc","charges","crea","race","dnr"), k = 5)
data_imp <- data_imp |> 
  dplyr::select(-c(wblc_imp, charges_imp, crea_imp, race_imp, dnr_imp, income, race))

#income,race
```
:::

```{r,echo=FALSE,include=FALSE}
data_scaled = data |> 
  dplyr::mutate(across(
    where(is.numeric),
    ~ as.numeric(scale(.x))
  ))

data_scaled <- data_scaled |> 
  na.omit() 

as_tibble(data_scaled)
```

```{r,echo=FALSE,include=FALSE}
set.seed(6)

split <- initial_split(data_scaled, prop = 0.8, strata = death)
train <- training(split)
test  <- testing(split)

folds <- vfold_cv(train, v = 10, strata = death)
```

# 3) Unsupervised Model : FAMD
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)
train <- train|> 
  dplyr::select(-id) 

res_famd <- FAMD(train, ncp = 5, graph = FALSE)

fviz_screeplot(res_famd)
```


## Optimal number of clusters
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

coords_famd <- res_famd$ind$coord  

fviz_nbclust(coords_famd, kmeans)
set.seed(6)
famd_km_res <- kmeans(coords_famd, centers = 2, nstart = 25)
```

## Clustering: Kmeans
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

coords_famd = as.data.frame(coords_famd)

colnames(coords_famd) = c("Dim1", "Dim2", "Dim3", "Dim4", "Dim5")

coords_famd$cluster = famd_km_res$cluster

plot_ly(
  data = coords_famd,
  x = ~Dim1,
  y = ~Dim2,
  z = ~Dim3,
  type = "scatter3d",
  mode = "markers",
  color = ~factor(cluster),
  colors = "Set2",
  marker = list(size = 3)
) %>%
  layout(
    title = "3D Scatterplot FAMD-Kmeans",
    scene = list(
      xaxis = list(title = "Dim 1"),
      yaxis = list(title = "Dim 2"),
      zaxis = list(title = "Dim 3")
    )
  )
```

## Evaluation of results
Clustering coerence is now evaluated on the test set
```{r,echo=FALSE,include=FALSE}
test <- test|> 
  select(-id) 
res_famd_test <- predict(res_famd, newdata = test)

coords_test <- as.data.frame(res_famd_test$coord)

colnames(coords_test) = c("Dim1", "Dim2", "Dim3", "Dim4", "Dim5")

test$cluster <- apply(coords_test, 1, function(x) {
  which.min(colSums((t(famd_km_res$centers) - x)^2))
})
```

### Random Forest and Feature importance
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

data_RF <- test
set.seed(6)
rf_model <- ranger(cluster ~ ., data = data_RF, mtry = 4, importance = "impurity_corrected")

importance_df <- data.frame(
  variable = names(rf_model$variable.importance),
  importance = rf_model$variable.importance)

importance_df <- importance_df[order(importance_df$importance, decreasing = TRUE), ]
ggplot(head(importance_df, 20), aes(x = reorder(variable, importance), y = importance)) +
  geom_bar(stat = "identity", fill = "#8FD4B8") +
  coord_flip() +
  labs(title = "Feature Importance",
       x = "Feature",
       y = "Importance") +
  theme_minimal()
```

### Patient Profile for each cluster
```{r}
df <- test %>% mutate(cluster = factor(cluster))

vars <- c("ca","dzgroup","dzclass","aps","charges","hday","d.time","slos","death","num.co","hospdead")
num_vars <- vars[sapply(df[vars], is.numeric)]
cat_vars <- setdiff(vars, num_vars)

# Boxplot numeriche in griglia 2 righe x 3 colonne
plot_num <- df %>%
  select(cluster, all_of(num_vars)) %>%
  pivot_longer(-cluster, names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = cluster)) +
  geom_boxplot(outlier.size = 0.6, alpha = 0.7) +
  facet_wrap(~ variable, scales = "free_y", ncol = 3, nrow = 2) +
  labs(title = "Boxplot variabili numeriche per cluster", x = "Cluster", y = NULL) +
  theme_minimal() +
  theme(legend.position = "none")

print(plot_num)

# Stampa le categoriali una per una (frequenze relative per cluster)
for(v in cat_vars){
  p <- df %>%
    select(cluster, !!sym(v)) %>%
    rename(category = !!sym(v)) %>%
    filter(!is.na(category)) %>%
    group_by(cluster, category) %>%
    summarise(n = n(), .groups = "drop") %>%
    group_by(cluster) %>%
    mutate(prop = n / sum(n)) %>%
    ggplot(aes(x = cluster, y = prop, fill = category)) +
    geom_col(position = position_fill(), color = "black") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    labs(title = paste("Distribuzione di", v, "per cluster"),
         x = "Cluster", y = "Proporzione", fill = v) +
    theme_minimal() +
    theme(legend.position = "bottom")
  print(p)
}
```



## NA evaluation
NAs seem to be missing at random 
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)

split <- initial_split(data_scaled, prop = 0.8, strata = death)
train <- training(split)
test  <- testing(split)

joined <- support2_na_analysis %>% inner_join(train %>% select(id), by = "id")
common_cols <- intersect(colnames(support2_na_analysis), colnames(train))
support_vars <- setdiff(colnames(support2_na_analysis), common_cols)
joined$cluster = coords_famd$cluster
data_NA <- joined %>% select(all_of(support_vars), cluster) |> select(-c(sfdm2, surv2m, sps, surv6m))
# Percentuali di NA per variabile e cluster ---
na_summary <- data_NA %>%
  group_by(cluster) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100))

# Heatmap delle percentuali di NA
mat <- as.matrix(na_summary[,-1])
rownames(mat) <- paste("Cluster", na_summary$cluster)

pheatmap(mat,
         cluster_rows = FALSE,
         cluster_cols = FALSE,
         main = "NA percentage by cluster")

```

#---------------------------------
# 4) Supervised Model: LR vs SVM

```{r,echo=FALSE,include=FALSE}
tot_data = data_imp
head(tot_data)

tot_data_scaled = tot_data |> 
  mutate(across(
    where(is.numeric),
    ~ as.numeric(scale(.x)))) |> 
  drop_na()
```

## The target variable
```{r}
ggplot(tot_data, aes(x = death, y = ..prop.., group = 1)) +
  geom_bar(fill = "#8FD4B8", color = "grey30") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "'death' Frequency",
    x = "Death",
    y = "Percentage"
  ) +
  theme_minimal(base_size = 14)

# balance the class?
```

## SVM Model
::: {style="font-size: 50%;"}
- Train Test split
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)

split <- initial_split(tot_data_scaled, prop = 0.8, strata = death)
train <- training(split)
test  <- testing(split)

folds <- vfold_cv(train, v = 10, strata = death)
```

- Recipe and Workflow
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

svm_rec <- recipe(death ~ ., data = train) |>                     
  step_dummy(all_nominal_predictors())  

svm_spec <- svm_linear(
  mode = "classification",
  cost = tune(),            
  #rbf_sigma = tune()      
) |> 
  set_engine("kernlab", kernel = "vanilladot")

# Workflow
svm_wf <- workflow() |>
  add_model(svm_spec) |>
  add_recipe(svm_rec)
```

- Tuning parameters: cost and complexity(rbf_sigma)
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)

svm_grid <- tibble(
  cost = c(0.1, 1, 10, 100),
  rbf_sigma = c(0.001, 0.01, 0.1, 1)
)

# Step 1: gridsearch
#svm_grid_res <- tune_grid(svm_wf, resamples = folds, grid = svm_grid, metrics = metric_set(recall))

# Step 2: bayesian tuning
#svm_bayes <- tune_bayes(svm_wf, resamples = folds, metrics = metric_set(recall), initial = svm_grid_res, iter = 3, control = control_bayes(verbose = TRUE))

# Best params
#best_params_svm <- tibble::tibble(cost = 1, rbf_sigma = 0.01) #auc
best_params_svm <- tibble::tibble(cost = 3.37)#, rbf_sigma = 0.00857) #recall
final_svm <- finalize_workflow(svm_wf, best_params_svm)

best_params_svm
```

- Results
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

svm_final_fit <- last_fit(final_svm, split)

preds_svm <- svm_final_fit %>% collect_predictions()

ms_svm <- yardstick::metric_set(yardstick::accuracy, yardstick::recall, yardstick::precision)

ms_svm(preds_svm, truth = death, estimate = .pred_class, event_level = "second")

#svm_final_fit |> collect_predictions() |> conf_mat(truth = death, estimate = .pred_class)
```
:::


## LR Model
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

# recipe
log_reg_rec <- recipe(death ~ ., data = train) |>                     
  step_dummy(all_nominal_predictors())  

# logistic regression penalized
log_reg_spec <- logistic_reg(
  mode = "classification",
  penalty = tune(),     
  mixture = 1             # 1 = LASSO, 0 = Ridge 
) |>
  set_engine("glmnet")

# Workflow
log_reg_wf <- workflow() |>
  add_model(log_reg_spec) |>
  add_recipe(log_reg_rec)   

# tuning
log_reg_grid <- tibble(
  penalty = c(0.001, 0.01, 0.1, 1)
)

#log_reg_grid_res <- tune_grid(log_reg_wf, resamples = folds, grid = log_reg_grid, metrics = metric_set(recall), control = control_grid(save_pred = TRUE))

#log_reg_bayes <- tune_bayes(log_reg_wf, resamples = folds, metrics = metric_set(recall), initial = log_reg_grid_res, iter = 3, control = control_bayes(verbose = TRUE, save_pred = TRUE))


#best_params_lr <- tibble::tibble(penalty = 0.01) #auc
best_params_lr <- tibble::tibble(penalty = 0.001) #recall
final_lr <- finalize_workflow(log_reg_wf, best_params_lr)

lr_final_fit <- last_fit(final_lr, split)

#lr_final_fit |>collect_predictions() |> conf_mat(truth = death, estimate = .pred_class)

preds_lr <- lr_final_fit %>% collect_predictions()

ms_lr <- yardstick::metric_set(yardstick::accuracy, yardstick::recall, yardstick::precision)

ms_lr(preds_lr, truth = death, estimate = .pred_class, event_level = "second")

```
## SVM vs LR: ROC curve
```{r,warning=FALSE,include=FALSE}
metrics_svm <- ms_svm(preds_svm, truth = death, estimate = .pred_class, event_level = "second") %>% mutate(model = "SVM")
metrics_lr  <- ms_lr(preds_lr,  truth = death, estimate = .pred_class, event_level = "second") %>% mutate(model = "LR")

combined <- dplyr::bind_rows(metrics_svm, metrics_lr) %>%
  dplyr::select(model, .metric, .estimate) %>%
  pivot_wider(names_from = model, values_from = .estimate)
```

```{r}
#| echo: true
#| code-fold: false
svm_test_preds <- collect_predictions(svm_final_fit)
lr_test_preds  <- collect_predictions(lr_final_fit)

svm_roc <- svm_test_preds %>%
  roc_curve(truth = death, .pred_0) %>%
  mutate(model = "SVM")

log_reg_roc <- lr_test_preds %>%
  roc_curve(truth = death, .pred_0) %>%
  mutate(model = "Logistic Regression")

bind_rows(svm_roc, log_reg_roc) %>%
  autoplot() +
  aes(color = model) +
  labs(title = "Test ROC Curve: SVM vs Logistic Regression")

```
## SVM vs LR: Confusion matrix and metrics
```{r}
#| echo: true
#| code-fold: false

#confusion matrix
p_svm <- autoplot(
  preds_svm %>% conf_mat(truth = death, estimate = .pred_class),
  type = "heatmap"
) +
  scale_fill_gradient(low = "#ccece6", high = "#006d2c") +
  ggtitle("Confusion Matrix – SVM") +
  theme_minimal(base_size = 14)

p_lr <- autoplot(
  preds_lr %>% conf_mat(truth = death, estimate = .pred_class),
  type = "heatmap"
) +
  scale_fill_gradient(low = "#c6dbef", high = "#08519c") +
  ggtitle("Confusion Matrix – Logistic Regression") +
  theme_minimal(base_size = 14)

# metrics
tbl <- combined %>%
  dplyr::rename(
    Metric = .metric,
    SVM = SVM,
    `Logistic Regression` = LR
  ) %>%
  kable(format = "html", digits = 3,
        caption = "Confronto tra metriche SVM vs LR") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped", "hover", "condensed")) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, background = "#f7f7f7")


p_svm | p_lr

combined %>%
  dplyr::rename(
    Metric = .metric,
    SVM = SVM,
    `Logistic Regression` = LR
  ) %>%
  kable("html", digits = 3, caption = "SVM vs LR") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped", "hover", "condensed")) %>%
  column_spec(1, bold = TRUE)
```
with very similar results, it is better to choose the easiest model: Logistic Regression

# Model interpretability
- SVM
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

# Bake training data with the SVM recipe (use TRAIN for interpretability)
svm_train_baked <- bake(prep(svm_rec, training = train), new_data = train)
X_train_svm <- svm_train_baked %>% dplyr::select(-death)

# Extract fitted kernlab model from last_fit
svm_fit_model <- svm_final_fit |> extract_fit_parsnip() |> pluck("fit")

svm_probs_train <- predict(svm_fit_model,
                           as.matrix(X_train_svm),
                           type="probabilities")[,2]


# Probabilities for positive class (1) on TRAIN
svm_predict_fun <- function(model, newdata) {
  predict(model, newdata, type = "probabilities")[, 2]
}
svm_train_probs <- svm_predict_fun(svm_fit_model, svm_train_baked %>% dplyr::select(-death))
svm_train_class <- ifelse(svm_train_probs >= 0.5, 1, 0)

# Build preds on TRAIN with TP/TN/FP/FN and explicit row index
svm_train_preds <- svm_train_baked %>%
  dplyr::mutate(
    .pred_prob  = svm_train_probs,
    .pred_class = factor(svm_train_class, levels = c(0, 1)),
    death       = factor(death, levels = c(0, 1)),
    case_type   = case_when(
      death == 1 & .pred_class == 1 ~ "TP",
      death == 0 & .pred_class == 0 ~ "TN",
      death == 0 & .pred_class == 1 ~ "FP",
      death == 1 & .pred_class == 0 ~ "FN"
    ),
    row_index   = row_number()
  )

# Lists of TRAIN indices by case type (quick scan for selecting observations)
tp_index <- svm_train_preds %>% dplyr::filter(case_type == "TP") %>% pull(row_index)
tn_index <- svm_train_preds %>% dplyr::filter(case_type == "TN") %>% pull(row_index)
fp_index <- svm_train_preds %>% dplyr::filter(case_type == "FP") %>% pull(row_index)
fn_index <- svm_train_preds %>% dplyr::filter(case_type == "FN") %>% pull(row_index)

cat("TP: ", tp_index, "\n")
cat("TN: ", tn_index, "\n")
cat("FP: ", fp_index, "\n")
cat("FN: ", fn_index, "\n")

```
- LR
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

# Bake TRAIN data
lr_train_baked <- bake(prep(log_reg_rec, training = train), new_data = train)
X_train_lr <- lr_train_baked %>% dplyr::select(-death)

# Extract the final fitted model
lr_model <- lr_final_fit %>% extract_fit_parsnip()

lr_fit_model <- lr_final_fit |> extract_fit_parsnip() |> pluck("fit")

# Predict probabilities for positive class (1) on TRAIN 
lr_train_probs <- predict(lr_fit_model, newx = as.matrix(lr_train_baked %>% dplyr::select(-death)), type = "response")[,1]

final_lr_fit <- workflows::fit(final_lr, data = train)
lr_train_probs <- predict(final_lr_fit, new_data = train, type = "prob")$.pred_1
lr_train_class <- ifelse(lr_train_probs >= 0.5, 1, 0)

lr_train_preds <- lr_train_baked %>%
  dplyr::mutate(
    .pred_prob  = lr_train_probs,
    .pred_class = factor(lr_train_class, levels = c(0,1)),
    death       = factor(death, levels = c(0,1)),
    case_type   = case_when(
      death == 1 & .pred_class == 1 ~ "TP",
      death == 0 & .pred_class == 0 ~ "TN",
      death == 0 & .pred_class == 1 ~ "FP",
      death == 1 & .pred_class == 0 ~ "FN"
    ),
    row_index = row_number()
  )

tp_index_lr <- lr_train_preds %>% dplyr::filter(case_type == "TP") %>% pull(row_index)
tn_index_lr <- lr_train_preds %>% dplyr::filter(case_type == "TN") %>% pull(row_index)
fp_index_lr <- lr_train_preds %>% dplyr::filter(case_type == "FP") %>% pull(row_index)
fn_index_lr <- lr_train_preds %>% dplyr::filter(case_type == "FN") %>% pull(row_index)

cat("TP: ", tp_index_lr, "\n")
cat("TN: ", tn_index_lr, "\n")
cat("FP: ", fp_index_lr, "\n")
cat("FN: ", fn_index_lr, "\n")

```


## Feature importance
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

w <- t(svm_fit_model@coef[[1]]) %*% svm_fit_model@xmatrix[[1]]
w <- as.numeric(w)

names(w) <- colnames(svm_fit_model@xmatrix[[1]])

svm_coefs <- tibble(
  feature = names(w),
  coefficient = w
) %>% arrange(desc(abs(coefficient)))

p_svm <- ggplot(svm_coefs, aes(x = reorder(feature, coefficient), y = coefficient)) +
  geom_col(fill = "#1b9e77") +
  coord_flip() +
  labs(
    title = "SVM Linear Coefficients (on TRAIN)",
    x = "Feature",
    y = "Coefficient"
  ) +
  theme_minimal(base_size = 14)

```

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

# Extract coefficients
coefs <- tidy(lr_model) %>% dplyr::filter(term != "(Intercept)") %>% arrange(term)
beta <- coefs$estimate
names(beta) <- coefs$term

# Project the coefficients directly onto TRAIN features
#    This gives the per-row contribution of each feature
lr_coef_proj <- X_train_lr %>%
  mutate_all(as.numeric) %>%
  { sweep(., 2, beta, `*`) }  # x_ij * beta_j

lr_coef_df <- tibble(
  feature = names(beta),
  coefficient = beta
) %>%
  arrange(desc(abs(coefficient)))

p_lr <- ggplot(lr_coef_df, aes(x = reorder(feature, coefficient), y = coefficient)) +
  geom_col(fill = "#7570b3") +
  coord_flip() +
  labs(
    title = "Logistic Regression Coefficients",
    x = "Feature",
    y = "Coefficient"
  ) +
  theme_minimal(base_size = 14)
```


```{r}
p_svm + p_lr 
```


## Shapley values
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

svm_pred <- Predictor$new(
  model = svm_fit_model,
  data  = svm_train_baked %>% dplyr::select(-death),
  y     = svm_train_baked$death,
  predict.function = svm_predict_fun)

obs_index <- c(2335, 2700, 4199, 7005)

# Calculate Shapley values
shap_list <- lapply(obs_index, function(i) {
  x_test <- svm_train_baked[i, -which(names(svm_train_baked)=="death"), drop = FALSE]
  shap <- Shapley$new(svm_pred, x.interest = x_test)
  df <- shap$results
  df$obs_id <- i
  df
})

shap_df <- dplyr::bind_rows(shap_list)

ggplot(shap_df, aes(x = feature, y = phi, fill = phi > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  scale_fill_manual(values = c("TRUE" = "#F07F28", "FALSE" = "#20B2AA")) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Shapley values – SVM",
    x = "Features",
    y = "Contribution (phi)"
  ) +
  facet_wrap(~ obs_id, ncol = 2)

```
```{r}
## Shapley values – Logistic Regression
#| echo: true
#| code-fold: true
#| code-summary: "code"

lr_pred <- Predictor$new(
  model = lr_fit_model,
  data  = X_train_lr,
  y     = lr_train_baked$death
)

obs_index <- c(2335, 2700, 4199, 7005)

# Calculate Shapley values
shap_list_lr <- lapply(obs_index, function(i) {
  x_test <- X_train_lr[i, , drop = FALSE]
  shap <- Shapley$new(lr_pred, x.interest = x_test)
  df <- shap$results
  df$obs_id <- i
  df
})

shap_df_lr <- dplyr::bind_rows(shap_list_lr)
# Visualizzazione
ggplot(shap_df_lr, aes(x = feature, y = phi, fill = phi > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  scale_fill_manual(values = c("TRUE" = "#F07F28", "FALSE" = "#20B2AA")) +
  theme_minimal(base_size = 14) +
  labs(
    title = "Shapley values – Logistic Regression",
    x = "Features",
    y = "Contribution (phi)"
  ) +
  facet_wrap(~ obs_id, ncol = 2)

```

## -----LIME
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

```

## -----Clustering on Shapley values



