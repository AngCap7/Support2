---
title: "Dati Complessi - Final Project"
author: "Mariateresa Russo e Angelo Capasso"
format:
  revealjs:
    theme: solarized
    highlight: pygments
    center: true
    transition: fade
    background-transition: slide
    slide-number: true
    preview-links: true
    code-fold: true
    code-summary: "code"
    font-family: "Times New Roman"
    font-size: 10px   
---


```{r setup, include = FALSE, echo = FALSE}
library(tidymodels)
library(tidyverse)
library(GGally)
library(ggplot2)
library(FactoMineR)
library(factoextra)
library(Rdimtools)
library(readr)
library(janitor)
library(knitr)
library(patchwork)
library(gridExtra)
library(lattice)
library(plotly)
library(clustrd)
library(mclust)
library(cluster)
library(VIM)
library(rpart)
library(kknn)
library(dplyr)
library(tidyr)
library(purrr)
library(rattle)
library(iml)
library(lime)
library(pheatmap)
library(treemapify)
library(plotly)
library(ranger)
library(yardstick)
library(tibble)
library(kableExtra)
library(ggbeeswarm)  
```

```{r, echo = FALSE, warning=FALSE, include=FALSE}
support2 <- read_csv("support2.csv")

data = support2
```

```{r, echo = FALSE, warning=FALSE, include=FALSE}
colnames(data) <- c("id", "age", "death", "sex", "hospdead", "slos", "d.time", "dzgroup", "dzclass", "num.co", "edu", "income", "scoma", "charges", "totcst", "totmcst", "avtisst", "race", "sps", "aps", "surv2m", "surv6m", "hday", "diabetes", "dementia", "ca", "prg2m", "prg6m", "dnr", "dnrday", "meanbp", "wblc", "hrt", "resp", "temp", "pafi", "alb", "bili", "crea", "sod", "ph", "glucose", "bun", "urine", "adlp", "adls", "sfdm2")

support2_na_analysis = data

data <- data |>
  dplyr::mutate(
    across(c(where(is.character), death, hospdead, 
                  diabetes, income, dementia), ~ factor(.x))) |> 
  dplyr::select(-c(scoma, sps, surv2m, surv6m, sfdm2))
```

# 1) Dataset

## Numerical Features

::: {style="font-size: 35%;"}
-   **age**: age\
-   **slos**: length of hospital stay (days)\
-   **d.time**: follow-up time (days)
-   **hday**: number of hospital days up to the clinical event (discharge or death)
-   **num.co**: number of comorbidities\
-   **edu**: years of education\
-   **charges**: charges billed to the patient\
-   **totcst**: cost estimated by the RCC index\
-   **totmcst**: actual cost billed considering bonuses\
-   **avtisst**: Therapeutic Intervention Scoring System (intensity of care)\
-   **aps**: Acute Physiology Score (vital conditions assessment)\
-   **meanbp**: mean blood pressure\
-   **wblc**: white blood cell count\
-   **hrt**: heart rate\
-   **resp**: respiratory rate\
-   **temp**: body temperature\
-   **pafi**: PaO2/FiO2 ratio\
-   **alb**: albumin\
-   **bili**: bilirubin\
-   **crea**: creatinine\
-   **sod**: sodium\
-   **ph**: blood pH\
-   **glucose**, **bun**, **urine**\
-   **adlp**, **adls**: scores indicating daily living activities\
-   **dnrday**: day of the DNR (do-not-resuscitate) decision\
-   **prg2m**, **prg6m**: survival probability at 2 and 6 months\
:::

## Categorical Features

::: {style="font-size: 60%;"}
-   **death**: 0 = alive, 1 = deceased\
-   **sex**: male / female\
-   **hospdead**: death in hospital (0/1)\
-   **diabetes**, **dementia**: presence/absence\
-   **dzgroup**: diagnostic group (e.g., Lung Cancer, Cirrhosis, ARF/MOSF)\
-   **dzclass**: broader diagnostic class\
-   **income**: income category\
-   **race**: white, black, other\
-   **ca**: cancer category (none / local / metastatic)\
-   **dnr**: DNR status (do-not-resuscitate)\
-   **sfdm2**: functional status at 2 months
:::

# 2) Esplorative Data Analysis

## Missing values{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
The data presents some features with relevant inflation of missing values (NA)
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
missing_summary <- tibble(
  variabile = names(data),
  n_na      = colSums(is.na(data)),
  perc_na   = colMeans(is.na(data)) * 100
) |>
  dplyr::filter(n_na > 0) |>         
  arrange(desc(perc_na))

ggplot(missing_summary, aes(x = reorder(variabile, perc_na), y = perc_na)) +
  geom_col(fill = "#8FD4B8") +
  coord_flip() +
  labs(title = "Features with missing values",
       x = "Feature", y = "% NA")
```
:::

## Numerical Features{style="font-size: 70%;"}

### Correlation matrix{style="font-size: 60%;"}
:::{style="font-size: 70%;"}
Globally, the most part of features present low correlation. Some considerable correlated features are: 
- totmcst, totcst, charges
- dnrday, slos
- adls, adlp
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
num_data <- data[, sapply(data, is.numeric)] %>% dplyr::select(-id)

corr_mat <- cor(num_data, use = "pairwise.complete.obs")

levelplot(
  corr_mat,
  scales = list(x = list(rot = 45)),
  xlab = " ",
  ylab = " ",
  main = "Correlation Heatmap",
  col.regions = colorRampPalette(c("#2A5783", "white", "#F07F28"))(100)
)
```
:::
## Numerical Features{style="font-size: 70%;"}

### Hierarchical Clustering{style="font-size: 60%;"}

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
dist_mat <- as.dist(1 - corr_mat)

hc <- hclust(dist_mat, method = "complete")

plot(hc, main = "Hierarchical Clustering")
```

## Categorical Features{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
Relative frequency of categorical features
```{r, warning=FALSE}
#| echo: true
#| code-fold: true
#| code-summary: "code"
data %>%
  dplyr::select(where(is.factor)) %>%
  tidyr::pivot_longer(cols = everything(), names_to = "variabile", values_to = "valore") %>%
  ggplot(aes(x = valore, y = ..prop.., group = 1, fill = valor)) +
  geom_bar(fill = "#8FD4B8") +
  facet_wrap(~ variabile, scales = "free") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Categorical Features - class Frequency",
       x = "Category", y = "Percentage") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none",
        strip.text = element_text(size = 10))

```
::: 

## Manage Missing Values{style="font-size: 70%;"}

::: {style="font-size: 50%;"}
-Remove features with more than 30% NA: bun, urine, glucose, adlp

```{r}
data <- data |> dplyr::select(-c(
  adlp, urine, glucose, bun, totmcst, alb, adls, bili, pafi, ph,
  prg2m, edu, prg6m, totcst))
```

-Remove features correlated with other features: avtisst, dnrday

```{r}
data <- data |> 
  dplyr::select(-c(avtisst, dnrday))
# adls adlp
# totmcst totcst charges
# aps avtisst
# dnrday slos
```

-Imputation for other features: income, wblc, charges, crea, race, dnr

```{r,warning=FALSE,echo=FALSE}
#| echo: false
#| code-fold: true
#| code-summary: "code"

data <- data |>
  dplyr::mutate(income = fct_explicit_na(income, na_level = "nd"))

library(VIM)
set.seed(6)
data_imp <- VIM::kNN(data, variable = c("wblc","charges","crea","race","dnr"), k = 5)
data_imp <- data_imp |> 
  dplyr::select(-c(wblc_imp, charges_imp, crea_imp, race_imp, dnr_imp, income, race))
```
:::

```{r,echo=FALSE,include=FALSE}
data_scaled = data |>
  mutate(across(where(is.numeric) & !matches("id"),
    ~ as.numeric(scale(.x))
  ))

data_scaled <- data_scaled |> 
  na.omit() 

as_tibble(data_scaled)
```

```{r,echo=FALSE,include=FALSE}
set.seed(6)

split <- initial_split(data_scaled, prop = 0.8, strata = death)
train <- training(split)
test  <- testing(split)

folds <- vfold_cv(train, v = 10, strata = death)
```

# 3) Unsupervised Model : FAMD{style="font-size: 70%;"}
:::{style="font-size: 60%;"}
Factor Analysis of Mixed Data (FAMD) is used for handling datasets with both numerical and categorical variables is:
- **Standardize numerical variables**  
  Center and scale all quantitative features so they contribute equally\
- **Encode and weight categorical variables**  
  Transform categorical features into disjunctive (dummy) coding and apply weights so each categorical variable contributes the same as a numerical one\
- **Construct the combined matrix**  
  Merge standardized numerical variables and weighted categorical variables into a single analysis matrix\
- **Apply Singular Value Decomposition (SVD)**  
  Perform SVD on the combined matrix to extract principal components that summarize the joint structure of numerical and categorical features\
:::

## Choose the best number of components{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
The choice of the best number of components followed the elbow method, the screeplot shows the quantity of inertia for each dimension
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)

res_famd <- FAMD(train |> dplyr::select(-id), ncp = 5, graph = FALSE)

fviz_screeplot(res_famd)
```
:::

## Optimal number of clusters{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
The choice of the optimal number of clusters is taken using the silhouette metric
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

coords_famd <- res_famd$ind$coord  

fviz_nbclust(coords_famd, kmeans)
set.seed(6)
famd_km_res <- kmeans(coords_famd, centers = 2, nstart = 25)
```
:::

## Clustering: Kmeans{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
Clustering is applied on the five dimensions reached with FAMD
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

coords_famd = as.data.frame(coords_famd)

colnames(coords_famd) = c("Dim1", "Dim2", "Dim3", "Dim4", "Dim5")

coords_famd$cluster = famd_km_res$cluster

plot_ly(
  data = coords_famd,
  x = ~Dim1,
  y = ~Dim2,
  z = ~Dim3,
  type = "scatter3d",
  mode = "markers",
  color = ~factor(cluster),
  colors = "Set2",
  marker = list(size = 3)
) %>%
  layout(
    title = "3D Scatterplot FAMD-Kmeans",
    scene = list(
      xaxis = list(title = "Dim 1"),
      yaxis = list(title = "Dim 2"),
      zaxis = list(title = "Dim 3")
    )
  )
```
:::

## Evaluation of results{style="font-size: 70%;"}
:::{style="font-size: 60%;"}
Clustering coerence is now evaluated on the test set. By training a surrogate model (Random Forest) with target variable the id cluster, the related feature importance is plotted to show which are the features that contributed the most into cluster separation. Then, for the two clusters, an ipothetic patient profile is presented
```{r,echo=FALSE,include=FALSE}
test_noid <- test|> 
  select(-id) 

res_famd_test <- predict(res_famd, newdata = test_noid)

coords_test <- as.data.frame(res_famd_test$coord)

colnames(coords_test) = c("Dim1", "Dim2", "Dim3", "Dim4", "Dim5")

test$cluster <- apply(coords_test, 1, function(x) {
  which.min(colSums((t(famd_km_res$centers) - x)^2))
})
```
:::

## Evaluation of results{style="font-size: 70%;"}
### Random Forest and Feature importance{style="font-size: 60%;"}

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

data_RF <- test
set.seed(6)
rf_model <- ranger(cluster ~ .-id, data = data_RF, mtry = 4, importance = "impurity_corrected")

importance_df <- data.frame(
  variable = names(rf_model$variable.importance),
  importance = rf_model$variable.importance)

importance_df <- importance_df[order(importance_df$importance, decreasing = TRUE), ]
ggplot(head(importance_df, 20), aes(x = reorder(variable, importance), y = importance)) +
  geom_bar(stat = "identity", fill = "#8FD4B8") +
  coord_flip() +
  labs(title = "Feature Importance",
       x = "Feature",
       y = "Importance") +
  theme_minimal()
```

## Evaluation of results{style="font-size: 70%;"}
### Patient Profile for each cluster{style="font-size: 60%;"}

```{r}
df <- test %>% mutate(cluster = factor(cluster))

vars <- c("ca", "dzgroup", "dzclass", "aps", "charges", "hday", "num.co", "d.time", "slos", "death", "hospdead", "age", "income", "crea", "meanbp", "hrt", "wblc", "diabetes", "dnr", "temp")

num_vars <- vars[sapply(df[vars], is.numeric)]
cat_vars <- setdiff(vars, num_vars)

plot_num <- df %>%
  select(cluster, all_of(num_vars)) %>%
  pivot_longer(-cluster, names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = cluster, y = value, fill = cluster)) +
  geom_boxplot(outlier.size = 0.6, alpha = 0.7) +
  facet_wrap(~ variable, scales = "free_y", ncol = 3, nrow = 4) +
  labs(title = "Boxplot of numeric vars per cluster", x = "Cluster", y = NULL) +
  theme_minimal() +
  theme(legend.position = "none")

print(plot_num)
```

## Evaluation of results{style="font-size: 70%;"}
### Patient Profile for each cluster{style="font-size: 60%;"}
```{r}
df_cat_long <- df %>%
  select(cluster, all_of(cat_vars)) %>%
  pivot_longer(
    cols = -cluster,
    names_to = "variable",
    values_to = "category"
  ) %>%
  filter(!is.na(category))  

ggplot(df_cat_long, aes(x = cluster, fill = category)) +
  geom_bar(position = "fill", color = "black") +
  facet_wrap(~ variable, scales = "free_y", ncol = 3) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    title = "Categorical vars distribution per cluster",
    x = "Cluster",
    y = "Proportion",
    fill = "Category"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

```

## NA evaluation{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
Considering the number of missing values for each feature in each cluster, missing values seem to be missing at random
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)

split <- initial_split(data_scaled, prop = 0.8, strata = death)
train <- training(split)
test  <- testing(split)

joined <- support2_na_analysis %>% inner_join(train %>% select(id), by = "id")
common_cols <- intersect(colnames(support2_na_analysis), colnames(train))
support_vars <- setdiff(colnames(support2_na_analysis), common_cols)
joined$cluster = coords_famd$cluster
data_NA <- joined %>% select(all_of(support_vars), cluster) |> select(-c(sfdm2, surv2m, sps, surv6m))

na_summary <- dplyr::summarise(
  dplyr::group_by(data_NA, cluster),
  dplyr::across(
    dplyr::everything(),
    ~ base::mean(base::is.na(.)) * 100))

# Heatmap
mat <- as.matrix(na_summary[,-1])
rownames(mat) <- paste("Cluster", na_summary$cluster)

pheatmap(mat,
         cluster_rows = FALSE,
         cluster_cols = FALSE,
         main = "NA percentage by cluster")

```
:::

# 4) Supervised Model: LR vs SVM{style="font-size: 70%;"}

```{r,echo=FALSE,include=FALSE}
tot_data = data_imp
head(tot_data)

tot_data_scaled = tot_data |> 
  select(-id) |> 
  mutate(across(
    where(is.numeric),
    ~ as.numeric(scale(.x)))) |> 
  drop_na()
```

## The target variable{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
The target variable death indicates whether a hospitalized patient died during or after their stay
```{r}
ggplot(tot_data, aes(x = death, y = ..prop.., group = 1)) +
  geom_bar(fill = "#8FD4B8", color = "grey30") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "'death' Frequency",
    x = "Death",
    y = "Percentage"
  ) +
  theme_minimal(base_size = 14)
```
:::

## SVM Model{style="font-size: 70%;"}
::: {style="font-size: 60%;"}
The model Support Vector classifier was trained to obtain the best classification for the target variable classes: Alive or Death. Procedure:
-   Train Test split
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)

split <- initial_split(tot_data_scaled, prop = 0.8, strata = death)
train <- training(split)
test  <- testing(split)

folds <- vfold_cv(train, v = 10, strata = death)
```

-   Recipe, Model specification and Workflow
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

svm_rec <- recipe(death ~ ., data = train) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors())


svm_spec <- svm_linear(
  mode = "classification",
  cost = best_params_svm$cost
) %>%
  set_engine("kernlab")

# Workflow
svm_wf <- workflow() %>%
  add_recipe(svm_rec) %>%
  add_model(svm_spec)
```

-   Tuning parameters: cost 
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

set.seed(6)

svm_grid <- tibble(
  cost = c(0.1, 1, 10, 100)
  #rbf_sigma = c(0.001, 0.01, 0.1, 1)
)

# Step 1: gridsearch
#svm_grid_res <- tune_grid(svm_wf, resamples = folds, grid = svm_grid, metrics = metric_set(recall))

# Step 2: bayesian tuning
#svm_bayes <- tune_bayes(svm_wf, resamples = folds, metrics = metric_set(recall), initial = svm_grid_res, iter = 3, control = control_bayes(verbose = TRUE))

# Best params
best_params_svm <- tibble::tibble(cost = 1) # rbf_sigma = 0.01) #auc
#best_params_svm <- tibble::tibble(cost = 3.37)#, rbf_sigma = 0.00857) #recall
final_svm <- finalize_workflow(svm_wf, best_params_svm)

best_params_svm
```

-   Results
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

svm_final_fit <- last_fit(svm_wf, split)

ms_svm <- yardstick::metric_set(yardstick::accuracy, yardstick::recall, yardstick::precision)

preds_svm <- collect_predictions(svm_final_fit)
ms_svm(preds_svm, truth = death, estimate = .pred_class, event_level = "second")
```
:::

## LR Model{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
A more interpretable and easier model, the Logistic Regression, is computed to evaluate which is the best model to use in this study. the procedure is the same of SVM, here the tuning parameter defines the Lasso penalty for implicit feature selection
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

# logistic regression penalized
log_reg_spec <- logistic_reg(
  mode = "classification",
  penalty = tune(),     
  mixture = 1             # 1 = LASSO, 0 = Ridge 
) |>
  set_engine("glmnet")

# Workflow
log_reg_wf <- workflow() |>
  add_model(log_reg_spec) |>
  add_recipe(svm_rec)   

# tuning
log_reg_grid <- tibble(
  penalty = c(0.001, 0.01, 0.1, 1)
)

#log_reg_grid_res <- tune_grid(log_reg_wf, resamples = folds, grid = log_reg_grid, metrics = metric_set(recall), control = control_grid(save_pred = TRUE))

#log_reg_bayes <- tune_bayes(log_reg_wf, resamples = folds, metrics = metric_set(recall), initial = log_reg_grid_res, iter = 3, control = control_bayes(verbose = TRUE, save_pred = TRUE))


best_params_lr <- tibble::tibble(penalty = 0.01) #auc
#best_params_lr <- tibble::tibble(penalty = 0.001) #recall
final_lr <- finalize_workflow(log_reg_wf, best_params_lr)

lr_final_fit <- last_fit(final_lr, split)

preds_lr  <- collect_predictions(lr_final_fit)

ms_lr <- yardstick::metric_set(yardstick::accuracy, yardstick::recall, yardstick::precision)

log_reg_spec
best_params_lr
ms_lr(preds_lr, truth = death, estimate = .pred_class, event_level = "second")
```
:::

## SVM vs LR: ROC curve{style="font-size: 70%;"}

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

svm_preds <- collect_predictions(svm_final_fit)
lr_preds  <- collect_predictions(lr_final_fit)

svm_roc <- svm_preds %>%
  roc_curve(truth = death, .pred_0) %>%
  dplyr::mutate(model = "SVM")

log_reg_roc <- lr_preds %>%
  roc_curve(truth = death, .pred_0) %>%
  mutate(model = "Logistic Regression")

bind_rows(svm_roc, log_reg_roc) %>%
  autoplot() +
  aes(color = model) +
  labs(title = "Test ROC Curve: SVM vs Logistic Regression")

```

```{r,warning=FALSE,include=FALSE}
metrics_svm <- ms_svm(preds_svm, truth = death, estimate = .pred_class, event_level = "second") %>% mutate(model = "SVM")
metrics_lr  <- ms_lr(preds_lr,  truth = death, estimate = .pred_class, event_level = "second") %>% mutate(model = "LR")

combined <- dplyr::bind_rows(metrics_svm, metrics_lr) %>%
  dplyr::select(model, .metric, .estimate) %>%
  pivot_wider(names_from = model, values_from = .estimate)
```


## SVM vs LR: Confusion matrix and metrics{style="font-size: 70%;"}

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
#| fig-width: 12
#| fig-height: 4
#| out-width: "100%"
#confusion matrix
mat_svm <- autoplot(
  preds_svm %>% conf_mat(truth = death, estimate = .pred_class),
  type = "heatmap"
) +
  scale_fill_gradient(low = "#ccece6", high = "#458B74") +
  ggtitle("Confusion Matrix – SVM") +
  theme_minimal(base_size = 14)

mat_lr <- autoplot(
  preds_lr %>% conf_mat(truth = death, estimate = .pred_class),
  type = "heatmap"
) +
  scale_fill_gradient(low = "#FFA54F", high = "#8B4513") +
  ggtitle("Confusion Matrix – Logistic Regression") +
  theme_minimal(base_size = 14)

# metrics
tbl <- combined %>%
  dplyr::rename(
    Metric = .metric,
    SVM = SVM,
    `Logistic Regression` = LR
  ) %>%
  kable(format = "html", digits = 3,
        caption = "Confronto tra metriche SVM vs LR") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped", "hover", "condensed")) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, background = "#f7f7f7")


mat_svm | mat_lr

combined %>%
  dplyr::rename(
    Metric = .metric,
    SVM = SVM,
    `Logistic Regression` = LR
  ) %>%
  kable("html", digits = 3, caption = "SVM vs LR") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped", "hover", "condensed")) %>%
  column_spec(1, bold = TRUE)
```


# Model interpretability{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
Interpretable machine learning is useful to understand the model decision. Logistic regression is a white-box model, by interpreting coefficients it is easy to understand how the model reasoned. By contrast, the linear SVC optimizes a hinge loss to maximize the margin between classes. Its coefficients define the orientation of the separating hyperplane, but they do not map to probabilities or intuitive effect sizes. The decision function depends heavily on support vectors, the critical points near the boundary, rather than on global relationships across all data. As a result, the reasoning behind predictions is tied to geometric separation rather than interpretable statistical associations. Since SVC is considered a black-box model, interpretable machine learning methods were adopted in order to interpret model coherence
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"

# Fit on train set
final_lr_fit <- workflows::fit(final_lr, data = train)
final_svm_fit <- workflows::fit(final_svm, data = train)

# Extract models
lr_model <- final_lr_fit %>% extract_fit_parsnip()
svm_model <- final_svm_fit %>% extract_fit_parsnip()

# Predictions on train
train_baked <- bake(prep(svm_rec, training = train), new_data = train)

# Logistic Regression
lr_probs <- predict(final_lr_fit, new_data = train, type = "prob")$.pred_1
lr_class <- ifelse(lr_probs >= 0.5, 1, 0)

# SVM 
svm_predict_fun <- function(model, newdata) {
  predict(model$fit, as.matrix(newdata), type = "probabilities")[,2]
}
svm_probs <- svm_predict_fun(svm_model, train_baked %>% select(-death))
svm_class <- ifelse(svm_probs >= 0.5, 1, 0)

# Add predictions to dataframe
train_preds <- train_baked %>%
  dplyr::mutate(
    lr_prob = lr_probs,
    lr_class = factor(lr_class, levels = c(0,1)),
    svm_prob = svm_probs,
    svm_class = factor(svm_class, levels = c(0,1)),
    death = factor(death, levels = c(0,1)),
    lr_case = case_when(
      death == 1 & lr_class == 1 ~ "TP",
      death == 0 & lr_class == 0 ~ "TN",
      death == 0 & lr_class == 1 ~ "FP",
      death == 1 & lr_class == 0 ~ "FN"
    ),
    svm_case = case_when(
      death == 1 & svm_class == 1 ~ "TP",
      death == 0 & svm_class == 0 ~ "TN",
      death == 0 & svm_class == 1 ~ "FP",
      death == 1 & svm_class == 0 ~ "FN"
    ),
    row_index = row_number()
  )

tp_lr <- train_preds %>% dplyr::filter(lr_case == "TP") %>% pull(row_index)
tn_lr <- train_preds %>% dplyr::filter(lr_case == "TN") %>% pull(row_index)
fp_lr <- train_preds %>% dplyr::filter(lr_case == "FP") %>% pull(row_index)
fn_lr <- train_preds %>% dplyr::filter(lr_case == "FN") %>% pull(row_index)

tp_svm <- train_preds %>% dplyr::filter(svm_case == "TP") %>% pull(row_index)
tn_svm <- train_preds %>% dplyr::filter(svm_case == "TN") %>% pull(row_index)
fp_svm <- train_preds %>% dplyr::filter(svm_case == "FP") %>% pull(row_index)
fn_svm <- train_preds %>% dplyr::filter(svm_case == "FN") %>% pull(row_index)
```
:::

## Feature importance{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
Feature importance is evaluated with two different methods for the two models:
- LR, models coefficients
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
# Logistic Regression (LASSO)
lr_coefs <- coef(lr_model$fit, s = best_params_lr$penalty) %>%
  as.matrix() %>%
  as.data.frame()
lr_coefs$feature <- rownames(lr_coefs)
colnames(lr_coefs)[1] <- "coefficient"
lr_coefs <- lr_coefs[-1,]  # remove intercept

p_lr <- ggplot(lr_coefs, aes(x = reorder(feature, coefficient), y = coefficient)) +
  geom_bar(stat = "identity", fill = "#FFA54F") +
  coord_flip() +
  ggtitle("Coefficients - Logistic Regression") +
  theme_minimal()
```

-SVM, summarised Shapley Values (Bee Swarm plot)
```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
predictor_svm <- Predictor$new(
  model = svm_model$fit,
  data = train_baked %>% select(-death),
  y = as.numeric(train_baked$death),
  predict.fun = function(model, newdata) predict(model, as.matrix(newdata), type = "probabilities")[,2]
)

shap_list <- lapply(1:min(200, nrow(train_baked)), function(i) {
  Shapley$new(predictor_svm, x.interest = train_baked[i,] %>% select(-death))
})

shap_values_all <- do.call(rbind, lapply(shap_list, function(x) x$results))

p_svm <- ggplot(shap_values_all, aes(x = phi, y = reorder(feature, abs(phi)), color = phi)) +
  geom_violin(fill = "#458B74", alpha = 0.7, color = "#458B74") +
  labs(
    title = "Bee Swarm Plot of Shapley Values - SVM",
    x = "Shapley Value",
    y = "Feature",
    color = "Shapley Value"
  ) +
  theme_minimal(base_size = 14)

```

```{r,echo=FALSE}
#| echo: true
#| code-fold: true
#| code-summary: "code"
#| fig-width: 12
#| fig-height: 4
#| out-width: "100%"

(p_lr | p_svm) &
  theme(
    text = element_text(size = 10),
    plot.title = element_text(size = 12),
    axis.title = element_text(size = 9),
    axis.text = element_text(size = 8),
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 9)
  )
```
:::

## Shapley values{style="font-size: 70%;"}
:::{style="font-size: 70%;"}
Shapley values were computed for the SVM predictions and compared with the logistic regression coefficients. They provide a local explanation of how each model makes predictions for individual observations. The analysis focused on observations for which the two models produced discordant predictions, in order to highlight differences in their decision mechanisms
```{r,include=FALSE}
# First 1 obs: fp in lr, tn in svm
# Second 1 obs: fn in lr, tp in svm
# Third 1 obs: fp in svm, tn in lr
# Fourth 1 obs: fn in svm, tp in lr
# Last 2 obs: the models agree
new_obs <- train_baked[c(697, 6793, 2990, 1079, 2324,2325), ] %>% select(-death)
```

```{r,include=FALSE}
# observations to plot
shap_list_svm <- lapply(1:6, function(i) {
  Shapley$new(predictor_svm, x.interest = new_obs[i, ])
})

# Predictor SVM
predictor_svm <- Predictor$new(
  model = svm_model$fit,
  data = new_obs,
  y = as.numeric(train_baked$death[1:6]),
  predict.fun = function(model, newdata) predict(model, as.matrix(newdata), type = "probabilities")[,2]
)

# SHAP for 6 observations
shap_list_svm <- lapply(1:6, function(i) Shapley$new(predictor_svm, x.interest = new_obs[i, ]))

shap_values_svm <- do.call(rbind, lapply(shap_list_svm, function(x) x$results)) %>%
  mutate(obs = rep(1:6, each = ncol(new_obs)))
```

```{r,include=FALSE}
lr_coef <- coef(lr_model$fit, s = best_params_lr$penalty) %>%
  as.matrix() %>%
  as.data.frame() %>%
  tibble::rownames_to_column(var = "feature") %>%
  dplyr::rename(coef = 2) %>%
  dplyr::filter(feature != "(Intercept)")


lr_contrib <- new_obs %>%
  mutate(obs = row_number()) %>%
  tidyr::pivot_longer(-obs, names_to = "feature", values_to = "value") %>%
  left_join(lr_coef, by = "feature") %>%
  mutate(phi = coef * value)
```

```{r,include=FALSE,echo=FALSE}
shap_values_svm <- shap_values_svm %>%
  dplyr::mutate(model = "SVM")

lr_contrib <- lr_contrib %>%
  dplyr::mutate(model = "LR")

shap_both <- bind_rows(
  shap_values_svm %>% dplyr::select(feature, phi, obs, model),
  lr_contrib      %>% dplyr::select(feature, phi, obs, model)
)
```
:::

---

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
obs1 <- shap_both %>% dplyr::filter(obs == 1)

ggplot(obs1, aes(x = reorder(feature, phi), y = phi, fill = phi > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip(clip = "off") +
  facet_wrap(~ model, ncol = 2, scales = "free_y") +
  scale_y_continuous(
    breaks = scales::pretty_breaks(n = 6),
    expand = expansion(mult = c(0.05, 0.25))) +
  scale_fill_manual(values = c("TRUE"="#CC5500", "FALSE"="#458B74")) +
  labs(
    title = "Observation 697 – FP LR / TN SVM",
    x = "Feature",
    y = "Contribution / Shapley Value")
```

---

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
obs2 <- shap_both %>% dplyr::filter(obs == 2)

ggplot(obs2, aes(x = reorder(feature, phi), y = phi, fill = phi > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip(clip = "off") +
  facet_wrap(~ model, ncol = 2, scales = "free_y") +
  scale_y_continuous(
    breaks = scales::pretty_breaks(n = 6),
    expand = expansion(mult = c(0.05, 0.25))) +
  scale_fill_manual(values = c("TRUE"="#CC5500", "FALSE"="#458B74")) +
  labs(
    title = "Observation 6793 – FN LR / TP SVM",
    x = "Feature",
    y = "Contribution / Shapley Value")
```

---

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
obs3 <- shap_both %>% dplyr::filter(obs == 3)

ggplot(obs3, aes(x = reorder(feature, phi), y = phi, fill = phi > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip(clip = "off") +
  facet_wrap(~ model, ncol = 2, scales = "free_y") +
  scale_y_continuous(
    breaks = scales::pretty_breaks(n = 6),
    expand = expansion(mult = c(0.05, 0.25))) +
  scale_fill_manual(values = c("TRUE"="#CC5500", "FALSE"="#458B74")) +
  labs(
    title = "Observation 2990 – TP LR / FN SVM",
    x = "Feature",
    y = "Contribution / Shapley Value")
```

---

```{r}
#| echo: true
#| code-fold: true
#| code-summary: "code"
obs4 <- shap_both %>% dplyr::filter(obs == 4)

ggplot(obs4, aes(x = reorder(feature, phi), y = phi, fill = phi > 0)) +
  geom_col(show.legend = FALSE) +
  coord_flip(clip = "off") +
  facet_wrap(~ model, ncol = 2, scales = "free_y") +
  scale_y_continuous(
    breaks = scales::pretty_breaks(n = 6),
    expand = expansion(mult = c(0.05, 0.25))) +
  scale_fill_manual(values = c("TRUE"="#CC5500", "FALSE"="#458B74")) +
  labs(
    title = "Observation 1079 – TN LR / FP SVM",
    x = "Feature",
    y = "Contribution / Shapley Value")
```

